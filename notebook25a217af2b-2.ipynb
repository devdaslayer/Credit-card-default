{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5552c619",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.984108,
     "end_time": "2024-07-23T18:17:33.952274",
     "exception": false,
     "start_time": "2024-07-23T18:17:30.968166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb720f5",
   "metadata": {
    "papermill": {
     "duration": 0.01877,
     "end_time": "2024-07-23T18:17:33.976629",
     "exception": false,
     "start_time": "2024-07-23T18:17:33.957859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4ea9a",
   "metadata": {
    "papermill": {
     "duration": 0.004819,
     "end_time": "2024-07-23T18:17:33.986621",
     "exception": false,
     "start_time": "2024-07-23T18:17:33.981802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f90e757",
   "metadata": {
    "papermill": {
     "duration": 0.31642,
     "end_time": "2024-07-23T18:17:34.308341",
     "exception": false,
     "start_time": "2024-07-23T18:17:33.991921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/credit-card-defaulter-hackathon/train_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load your training dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m train_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/credit-card-defaulter-hackathon/train_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Remove white spaces from column names\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/credit-card-defaulter-hackathon/train_data.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your training dataset\n",
    "print(\"Loading training data...\")\n",
    "train_data = pd.read_csv('/kaggle/input/credit-card-defaulter-hackathon/train_data.csv')\n",
    "print(\"Training data loaded.\")\n",
    "\n",
    "# Remove white spaces from column names\n",
    "print(\"Removing white spaces from column names...\")\n",
    "train_data.columns = train_data.columns.str.strip()\n",
    "print(\"White spaces removed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf844d",
   "metadata": {
    "papermill": {
     "duration": 0.157665,
     "end_time": "2024-07-23T18:17:34.471451",
     "exception": false,
     "start_time": "2024-07-23T18:17:34.313786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ea492",
   "metadata": {
    "papermill": {
     "duration": 0.005668,
     "end_time": "2024-07-23T18:17:34.482975",
     "exception": false,
     "start_time": "2024-07-23T18:17:34.477307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e8666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T18:17:34.496565Z",
     "iopub.status.busy": "2024-07-23T18:17:34.496148Z",
     "iopub.status.idle": "2024-07-23T18:17:34.965191Z",
     "shell.execute_reply": "2024-07-23T18:17:34.963662Z"
    },
    "papermill": {
     "duration": 0.47939,
     "end_time": "2024-07-23T18:17:34.968264",
     "exception": false,
     "start_time": "2024-07-23T18:17:34.488874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify non-numerical columns\n",
    "print(\"Identifying non-numerical columns...\")\n",
    "non_numerical_cols = train_data.select_dtypes(include=['object']).columns\n",
    "print(f\"Non-numerical columns: {non_numerical_cols}\")\n",
    "\n",
    "# Apply one-hot encoding to non-numerical columns on the training data\n",
    "print(\"Applying one-hot encoding...\")\n",
    "train_data = pd.get_dummies(train_data, columns=non_numerical_cols, drop_first=True)\n",
    "print(\"One-hot encoding applied.\")\n",
    "\n",
    "# Define features and target variable\n",
    "print(\"Defining features and target variable...\")\n",
    "X = train_data.drop(['ID', 'TARGET'], axis=1)\n",
    "y = train_data['TARGET']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\"Data split completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0401ea",
   "metadata": {
    "papermill": {
     "duration": 0.006021,
     "end_time": "2024-07-23T18:17:34.980798",
     "exception": false,
     "start_time": "2024-07-23T18:17:34.974777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature selection and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f34d02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T18:17:34.996241Z",
     "iopub.status.busy": "2024-07-23T18:17:34.995310Z",
     "iopub.status.idle": "2024-07-23T18:18:02.602373Z",
     "shell.execute_reply": "2024-07-23T18:18:02.600707Z"
    },
    "papermill": {
     "duration": 27.618051,
     "end_time": "2024-07-23T18:18:02.605325",
     "exception": false,
     "start_time": "2024-07-23T18:17:34.987274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train an XGBoost Classifier on the raw data\n",
    "print(\"Training initial XGBoost model...\")\n",
    "xgb = XGBClassifier(random_state=42, scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]))\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"Initial XGBoost model trained.\")\n",
    "\n",
    "# Feature selection using XGBoost feature importances\n",
    "print(\"Applying feature selection using XGBoost...\")\n",
    "selector = SelectFromModel(xgb, threshold='mean', prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "print(\"Feature selection applied.\")\n",
    "\n",
    "# Parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79347620",
   "metadata": {
    "papermill": {
     "duration": 0.006321,
     "end_time": "2024-07-23T18:18:02.618710",
     "exception": false,
     "start_time": "2024-07-23T18:18:02.612389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda78ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T18:18:02.634069Z",
     "iopub.status.busy": "2024-07-23T18:18:02.633606Z",
     "iopub.status.idle": "2024-07-23T18:23:57.830036Z",
     "shell.execute_reply": "2024-07-23T18:23:57.828621Z"
    },
    "papermill": {
     "duration": 355.213725,
     "end_time": "2024-07-23T18:23:57.838930",
     "exception": false,
     "start_time": "2024-07-23T18:18:02.625205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Starting grid search for parameter tuning...\")\n",
    "grid_search = GridSearchCV(estimator=XGBClassifier(random_state=42, scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1])),\n",
    "                           param_grid=param_grid, scoring='roc_auc', cv=3, verbose=1)\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "print(\"Grid search completed.\")\n",
    "\n",
    "# Best parameters and model from GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(best_params)\n",
    "\n",
    "# Make predictions on the test set\n",
    "print(\"Making predictions on the test set...\")\n",
    "y_pred = best_xgb.predict(X_test_selected)\n",
    "y_pred_proba = best_xgb.predict_proba(X_test_selected)[:, 1]\n",
    "print(\"Predictions made.\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluating the model...\")\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"XGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"XGBoost ROC AUC Score:\")\n",
    "print(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f69850",
   "metadata": {
    "papermill": {
     "duration": 0.006383,
     "end_time": "2024-07-23T18:23:57.852025",
     "exception": false,
     "start_time": "2024-07-23T18:23:57.845642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff6da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T18:23:57.867619Z",
     "iopub.status.busy": "2024-07-23T18:23:57.867192Z",
     "iopub.status.idle": "2024-07-23T18:23:58.889862Z",
     "shell.execute_reply": "2024-07-23T18:23:58.888569Z"
    },
    "papermill": {
     "duration": 1.03442,
     "end_time": "2024-07-23T18:23:58.893285",
     "exception": false,
     "start_time": "2024-07-23T18:23:57.858865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load your test dataset\n",
    "print(\"Loading test data...\")\n",
    "test_data = pd.read_csv('/kaggle/input/credit-card-defaulter-hackathon/test_data.csv')\n",
    "print(\"Test data loaded.\")\n",
    "\n",
    "# Remove white spaces from column names\n",
    "print(\"Removing white spaces from column names in test data...\")\n",
    "test_data.columns = test_data.columns.str.strip()\n",
    "print(\"White spaces removed.\")\n",
    "\n",
    "# Apply one-hot encoding to non-numerical columns on the test data\n",
    "print(\"Applying one-hot encoding to test data...\")\n",
    "test_data = pd.get_dummies(test_data, columns=non_numerical_cols, drop_first=True)\n",
    "print(\"One-hot encoding applied to test data.\")\n",
    "\n",
    "# Ensure the test dataset has the same columns as the training dataset\n",
    "print(\"Aligning test data columns with training data...\")\n",
    "for c in X.columns:\n",
    "    if c not in test_data.columns:\n",
    "        test_data[c] = 0\n",
    "test_data = test_data[X.columns]\n",
    "print(\"Test data columns aligned.\")\n",
    "\n",
    "# Transform the test data using the same feature selection\n",
    "print(\"Applying feature selection to test data...\")\n",
    "test_data_selected = selector.transform(test_data)\n",
    "print(\"Feature selection applied to test data.\")\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "print(\"Making predictions on the test dataset...\")\n",
    "test_predictions = best_xgb.predict(test_data_selected)\n",
    "test_probabilities = best_xgb.predict_proba(test_data_selected)[:, 1]\n",
    "print(\"Predictions on test dataset made.\")\n",
    "\n",
    "# Create a DataFrame with IDs and predictions\n",
    "print(\"Creating results DataFrame...\")\n",
    "results_df = pd.DataFrame({\n",
    "    'ID': pd.read_csv('/kaggle/input/credit-card-defaulter-hackathon/test_data.csv')['ID'],  # Load IDs again for submission\n",
    "    'Prediction': test_predictions\n",
    "})\n",
    "print(\"Results DataFrame created.\")\n",
    "\n",
    "# Save the results to a CSV file\n",
    "print(\"Saving results to CSV...\")\n",
    "results_df.to_csv('sample_submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8754041,
     "sourceId": 80991,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 391.85488,
   "end_time": "2024-07-23T18:23:59.630374",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-23T18:17:27.775494",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
